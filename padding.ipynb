{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c22917",
   "metadata": {},
   "source": [
    "병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84c4a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e66b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d62db492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person'],\n",
       " ['knew', 'secret'],\n",
       " ['secret', 'kept', 'huge', 'secret'],\n",
       " ['huge', 'secret'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'secret'],\n",
       " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       " ['barber', 'went', 'huge', 'mountain']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokend_list = sent_tokenize(text)\n",
    "all_pr_word={}\n",
    "pr_data=[]\n",
    "불용성단어=set(stopwords.words('english'))\n",
    "for sent in sent_tokend_list:\n",
    "    word_tokened_list = word_tokenize(sent)\n",
    "    l=[]\n",
    "    for word in word_tokened_list:\n",
    "        lower_word = word.lower()\n",
    "        if lower_word not in 불용성단어:\n",
    "            if len(lower_word)>2:\n",
    "                l.append(lower_word) #살아남은단어 리스트\n",
    "                if lower_word not in all_pr_word:\n",
    "                    all_pr_word[lower_word]=0\n",
    "                all_pr_word[lower_word]+=1\n",
    "    pr_data.append(l)\n",
    "pr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655ba316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(pr_data)\n",
    "encoded = tk.texts_to_sequences(pr_data)\n",
    "encoded #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91dc573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_l = max(len(x) for x in encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee3f11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in encoded:\n",
    "    while len(i)<max_l:\n",
    "        i.append(0) #max_l길이에 맞춰 0을 추가한다.\n",
    "data=np.array(encoded)     \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68452e",
   "metadata": {},
   "source": [
    "## 2. 케라스 전처리 도구로 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6264773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(pr_data) #정수 인덱스 사전\n",
    "encoded = tk.texts_to_sequences(pr_data) #인코딩\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e38e107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_data=pad_sequences(encoded,padding='post',maxlen=5) #encoded리스트를 행렬로 패딩\n",
    "end_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ad8729c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_data=pad_sequences(encoded,padding='post',truncating='post',maxlen=5)\n",
    "#벡터의 길이 5, 진짜 데이터 전방, 데이터 손실을 뒤에서\n",
    "end_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8c1c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 14, 14, 14, 14, 14],\n",
       "       [ 1,  8,  5, 14, 14, 14, 14],\n",
       "       [ 1,  3,  5, 14, 14, 14, 14],\n",
       "       [ 9,  2, 14, 14, 14, 14, 14],\n",
       "       [ 2,  4,  3,  2, 14, 14, 14],\n",
       "       [ 3,  2, 14, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  2, 14, 14, 14, 14],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13, 14, 14, 14]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=len(tk.word_index)+1\n",
    "end_data=pad_sequences(encoded,padding='post',truncating='post',value=v)\n",
    "end_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdb06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
